{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.helpers import scan\n",
    "\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import plotly as py\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import datetime as dt\n",
    "import pickle\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import helpers as hp\n",
    "from helpers import timer \n",
    "import model.queries as qrs\n",
    "\n",
    "import os.path\n",
    "from os import path\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ipwhois\n",
      "  Downloading ipwhois-1.2.0-py2.py3-none-any.whl (73 kB)\n",
      "\u001b[K     |████████████████████████████████| 73 kB 4.3 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting dnspython<=2.0.0\n",
      "  Downloading dnspython-2.0.0-py3-none-any.whl (208 kB)\n",
      "\u001b[K     |████████████████████████████████| 208 kB 17.3 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: dnspython, ipwhois\n",
      "Successfully installed dnspython-2.0.0 ipwhois-1.2.0\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 20.3.4 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ipwhois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting plotly\n",
      "  Downloading plotly-4.14.3-py2.py3-none-any.whl (13.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 13.2 MB 16.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting retrying>=1.3.3\n",
      "  Downloading retrying-1.3.3.tar.gz (10 kB)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from plotly) (1.11.0)\n",
      "Building wheels for collected packages: retrying\n",
      "  Building wheel for retrying (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for retrying: filename=retrying-1.3.3-py3-none-any.whl size=11429 sha256=c7b9cd54dbba54e6d98429694dfdfaa69fd7697621f927b5125dedf224ea904e\n",
      "  Stored in directory: /root/.cache/pip/wheels/c4/a7/48/0a434133f6d56e878ca511c0e6c38326907c0792f67b476e56\n",
      "Successfully built retrying\n",
      "Installing collected packages: retrying, plotly\n",
      "Successfully installed plotly-4.14.3 retrying-1.3.3\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 20.3.4 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "def scan_gen(scan):\n",
    "    while True:\n",
    "        try:\n",
    "            yield next(scan)['_source']\n",
    "        except:\n",
    "            break\n",
    "\n",
    "def ps_trace_hashes(dt,src, dest,include=[\"timestamp\",\"route-sha1\",\"hops\",\"destination_reached\",\"src\",\"dest\",\"looping\",\"path_complete\"]):\n",
    "    query = {\n",
    "      \"query\" : {\n",
    "        \"bool\" : {\n",
    "          \"must\" : [\n",
    "            {\n",
    "              \"range\" : {\n",
    "                \"timestamp\" : {\n",
    "                  \"gt\" : dt[0],\n",
    "                  \"lte\": dt[1]\n",
    "                }\n",
    "              }\n",
    "            },\n",
    "            {\n",
    "              \"term\" : {\n",
    "                'src' : {\n",
    "                  \"value\" : src\n",
    "                }\n",
    "              }\n",
    "            },\n",
    "            {\n",
    "              \"term\" : {\n",
    "                'dest' : {\n",
    "                  \"value\" : dest\n",
    "                }\n",
    "              }\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "#     print(str(query).replace(\"\\'\", \"\\\"\"))\n",
    "    try:\n",
    "        return scan_gen(scan(hp.es,index=\"ps_trace\",query=query, _source=include, filter_path=['_scroll_id', '_shards', 'hits.hits._source']))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "        \n",
    "def getMeanLoss(dt, src, dest):\n",
    "    q = {\n",
    "          \"size\" : 0,\n",
    "          \"query\" : {  \n",
    "            \"bool\" : {\n",
    "              \"must\" : [\n",
    "                {\n",
    "                  \"range\" : {\n",
    "                    \"timestamp\" : {\n",
    "                      \"from\" : dt[0],\n",
    "                      \"to\" : dt[1]\n",
    "                    }\n",
    "                  }\n",
    "                },\n",
    "                {\n",
    "                  \"term\" : {\n",
    "                    \"src\" : src\n",
    "                  }\n",
    "                },\n",
    "                {\n",
    "                  \"term\" : {\n",
    "                    \"dest\" : dest\n",
    "                  }\n",
    "                }\n",
    "              ]\n",
    "            }\n",
    "          },\n",
    "          \"aggs\": {\n",
    "            \"packet_loss\": {\n",
    "              \"avg\": {\n",
    "                \"field\": \"packet_loss\"\n",
    "              }\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "#     print(str(q).replace(\"\\'\", \"\\\"\"))\n",
    "    \n",
    "    data = hp.es.search(index='ps_packetloss', body=q, \n",
    "                _source=[ \"packet_loss\"])\n",
    "\n",
    "    return data['aggregations']['packet_loss']['value']\n",
    "\n",
    "    \n",
    "def ps_packetloss(dt, src, dest, include=[\"timestamp\",\"src\",\"dest\",\"packet_loss\"]):\n",
    "    query = {\n",
    "      \"query\" : {\n",
    "        \"bool\" : {\n",
    "          \"must\" : [\n",
    "            {\n",
    "              \"range\" : {\n",
    "                \"timestamp\" : {\n",
    "                  \"gt\" : dt[0],\n",
    "                  \"lte\": dt[1]\n",
    "                }\n",
    "              }\n",
    "            },\n",
    "            {\n",
    "              \"term\" : {\n",
    "                'src' : {\n",
    "                  \"value\" : src\n",
    "                }\n",
    "              }\n",
    "            },\n",
    "            {\n",
    "              \"term\" : {\n",
    "                'dest' : {\n",
    "                  \"value\" : dest\n",
    "                }\n",
    "              }\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "#     print(str(query).replace(\"\\'\", \"\\\"\"))\n",
    "    try:\n",
    "        return scan_gen(scan(hp.es,index=\"ps_packetloss\",query=query, _source=include, filter_path=['_scroll_id', '_shards', 'hits.hits._source']))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "        \n",
    "def ps_trace(es, dt, src, dest):\n",
    "    scan_gen = ps_trace_hashes(dt, src, dest)\n",
    "    data = []\n",
    "    hashes = {}\n",
    "    records = 0\n",
    "\n",
    "    for meta in scan_gen:\n",
    "        data.append(meta)\n",
    "#         print(meta)\n",
    "        if 'route-sha1' in data[records]:\n",
    "#         for doc in meta:\n",
    "            hashes[meta['route-sha1']] = meta['hops']\n",
    "        records += 1\n",
    "        if not records % 500000:\n",
    "            print(records)\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    if len(data)>0:\n",
    "        df['dt'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
    "    return df\n",
    "\n",
    "dt = hp.GetTimeRanges('2021-03-02 07:00','2021-03-12 07:00')\n",
    "\n",
    "# dt = hp.GetTimeRanges('2021-03-01 07:01','2021-03-01 07:30')\n",
    "print('Done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all tested pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = qrs.queryAllTestedPairs(dt)\n",
    "pairsDf = pd.DataFrame(pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get ps_trace data pair by pair and store all pairs in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pairs in ps_trace 2832\n"
     ]
    }
   ],
   "source": [
    "tracedata = []\n",
    "@timer\n",
    "def getTraceData():\n",
    "#     tracedata = []\n",
    "    i = 0\n",
    "    for src, dest in pairsDf[pairsDf['idx']=='ps_packetloss'][['src', 'dest']].values:\n",
    "        data = ps_trace(hp.es, dt, src, dest)\n",
    "        if len(data)>0:\n",
    "#             tracedata.append({'src': src, 'dest': dest, 'data':data})\n",
    "            tracedata.append(data)\n",
    "        i+=1\n",
    "    return tracedata\n",
    "\n",
    "# save to a file\n",
    "# tracedata = getTraceData()\n",
    "# with open('/workspace/data/tracedata.pkl','wb') as outfile:\n",
    "#     pickle.dump(tracedata,outfile)\n",
    "\n",
    "# retrieve from file\n",
    "with open(\"/workspace/data/tracedata.pkl\", 'rb') as pickle_file:\n",
    "    tracedata = pickle.load(pickle_file)\n",
    "\n",
    "print('Number of pairs in ps_trace',len(tracedata))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the packet loss between each two traceroute measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @timer\n",
    "def processAndWrite2File(df, filename):\n",
    "    df[['loss', 'path_changed']] = df.apply(calcLossBetweenMeasures, axis=1)\n",
    "    with open(filename,\"wb\") as f:\n",
    "        pickle.dump(df,f)\n",
    "        \n",
    "        \n",
    "def calcLossBetweenMeasures(row):\n",
    "    ploss = None\n",
    "    pathChanged = 1\n",
    "    if row['route-sha1'] == row['route-sha1_prev']:\n",
    "        period = [row['timestamp_prev'], row['timestamp']]\n",
    "        ploss = getMeanLoss(period, row['src'], row['dest'])\n",
    "        pathChanged = 0\n",
    "\n",
    "    return pd.Series([ploss, pathChanged])\n",
    "\n",
    "\n",
    "def calculatePathLoss(trace_df):\n",
    "    # sort data before calculating\n",
    "    trace_df = trace_df.sort_values('timestamp', ascending=True)\n",
    "    if 'route-sha1' in trace_df.columns:\n",
    "        # get the previous row value\n",
    "        trace_df['dt_prev'] = trace_df.dt.shift(1)\n",
    "        trace_df['timestamp_prev'] = trace_df.timestamp.shift(1,fill_value=0)\n",
    "\n",
    "        trace_df['route-sha1_prev'] = trace_df['route-sha1'].shift(1)\n",
    "\n",
    "        filename = f\"/workspace/data/dfs/{trace_df['src'].unique()[0]}-{trace_df['dest'].unique()[0]}.pkl\"\n",
    "\n",
    "        # write to a pickle file\n",
    "        if path.exists(filename):\n",
    "            if os.path.getsize(filename) > 0: \n",
    "                with open(filename, 'rb') as pickle_file:\n",
    "                    ff = pickle.load(pickle_file)\n",
    "\n",
    "                if len(ff) != len(trace_df):\n",
    "#                     print('File not OK. Write!', len(ff), len(trace_df))\n",
    "                    processAndWrite2File(trace_df, filename)\n",
    "            else: processAndWrite2File(trace_df, filename)\n",
    "        else:\n",
    "            processAndWrite2File(trace_df, filename)\n",
    "\n",
    "\n",
    "    return trace_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the calculations in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 'addPacketLoss2Df' in 5547.9736 secs\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "@timer\n",
    "def addPacketLoss2Df():\n",
    "    pool = multiprocessing.Pool()\n",
    "    result = pool.map(calculatePathLoss, tracedata)\n",
    "    return result\n",
    "\n",
    "tracedata = addPacketLoss2Df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveData(df, file_name):\n",
    "    with open(f\"/workspace/data/{file_name}.pkl\",\"wb\") as f:\n",
    "        pickle.dump(df,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the updated pair data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveData(tracedata, 'tracedata_with_loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a dictionarry of hashes, also merge all dataframes while looping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique hashes: 2792\n",
      "Total number of measures: 5098\n"
     ]
    }
   ],
   "source": [
    "hashDict = {}\n",
    "mergedDf = pd.DataFrame()\n",
    "\n",
    "def getHashes(row):\n",
    "    if 'route-sha1' in row:\n",
    "        if row['route-sha1'] not in hashDict.keys():\n",
    "#             print(row['hops'])\n",
    "            hashDict[row['route-sha1']] = row['hops']\n",
    "\n",
    "i = 0\n",
    "for df in tracedata:\n",
    "    df.apply(getHashes, axis=1)\n",
    "    mergedDf = mergedDf.append(df)\n",
    "    i+=1\n",
    "\n",
    "print('Number of unique hashes:', len(hashDict))\n",
    "print('Total number of measures:', len(mergedDf))\n",
    "\n",
    "saveData(hashDict, 'hashDict')\n",
    "saveData(mergedDf, 'mergedDf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hashDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a dictionary of all hops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique hops: 2302\n"
     ]
    }
   ],
   "source": [
    "hopsDict = {}\n",
    "\n",
    "for hashKey, hops in list(hashDict.items()):\n",
    "    for hop in hops:\n",
    "        temp = []\n",
    "        if hop in hopsDict.keys():\n",
    "            temp = hopsDict[hop]['hashes']\n",
    "#             if len(temp) > 300:\n",
    "            if hashKey not in temp:\n",
    "                temp.append(hashKey)\n",
    "#             print(len(temp))\n",
    "            hopsDict[hop] = {'hashes': temp, 'num_of_unique_hashes': len(temp)}\n",
    "        else: hopsDict[hop] = {'hashes': [hashKey], 'num_of_unique_hashes': 1}\n",
    "#         print(hop, temp)\n",
    "\n",
    "print(f'Number of unique hops: {len(hopsDict)}')\n",
    "saveData(hopsDict, 'hopsDict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a hash dataframe and encode the hops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['hash']\n",
    "cols = cols + list(hopsDict.keys())\n",
    "\n",
    "hashDf = pd.DataFrame(columns=cols)\n",
    "hashDf['hash'] = hashDict.keys()\n",
    "hashDf[cols[1:]] = 0\n",
    "\n",
    "for hop in hopsDict.keys():\n",
    "    hashDf[hop] =  np.where(hashDf['hash'].isin(hopsDict[hop]['hashes']), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hash</th>\n",
       "      <th>109.105.124.65</th>\n",
       "      <th>109.105.97.57</th>\n",
       "      <th>109.105.97.51</th>\n",
       "      <th>192.16.166.86</th>\n",
       "      <th>192.16.166.85</th>\n",
       "      <th>192.16.166.213</th>\n",
       "      <th>192.16.166.2</th>\n",
       "      <th>117.103.111.233</th>\n",
       "      <th>117.103.105.191</th>\n",
       "      <th>...</th>\n",
       "      <th>72.36.80.78</th>\n",
       "      <th>72.36.80.30</th>\n",
       "      <th>146.57.252.194</th>\n",
       "      <th>146.57.252.222</th>\n",
       "      <th>146.57.252.225</th>\n",
       "      <th>146.57.253.217</th>\n",
       "      <th>129.93.6.177</th>\n",
       "      <th>129.93.5.165</th>\n",
       "      <th>72.36.80.80</th>\n",
       "      <th>72.36.96.254</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e64b202e37888601fca7863026cb9f2bb8fc5f8a</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2a64d0017fe4bdf740ef778913b58508c575e000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6f922ee6b569a14699906d7f687a6149235bab47</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ef8add2f0a2bb52c41c2899777939ac584fcd477</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e8a72e214be0dbfa37c68abf7bd136a00b84ec77</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2787</th>\n",
       "      <td>e4823fa9386f56d71c2e3e3b2bbdf36134358e8a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2788</th>\n",
       "      <td>1100059b5eb4d7ce2b1dc9b3fd629654095c026c</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2789</th>\n",
       "      <td>30ad77626c69497c2e0c335578eff5485d35882e</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2790</th>\n",
       "      <td>fda2fffc92f9383712946b02f3065af9c541164a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2791</th>\n",
       "      <td>a62e1a40c496b0ce0f252b245f2871f527716dcb</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2792 rows × 2303 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          hash  109.105.124.65  109.105.97.57  \\\n",
       "0     e64b202e37888601fca7863026cb9f2bb8fc5f8a               1              1   \n",
       "1     2a64d0017fe4bdf740ef778913b58508c575e000               1              1   \n",
       "2     6f922ee6b569a14699906d7f687a6149235bab47               1              0   \n",
       "3     ef8add2f0a2bb52c41c2899777939ac584fcd477               1              0   \n",
       "4     e8a72e214be0dbfa37c68abf7bd136a00b84ec77               1              0   \n",
       "...                                        ...             ...            ...   \n",
       "2787  e4823fa9386f56d71c2e3e3b2bbdf36134358e8a               0              0   \n",
       "2788  1100059b5eb4d7ce2b1dc9b3fd629654095c026c               0              0   \n",
       "2789  30ad77626c69497c2e0c335578eff5485d35882e               0              0   \n",
       "2790  fda2fffc92f9383712946b02f3065af9c541164a               0              0   \n",
       "2791  a62e1a40c496b0ce0f252b245f2871f527716dcb               0              0   \n",
       "\n",
       "      109.105.97.51  192.16.166.86  192.16.166.85  192.16.166.213  \\\n",
       "0                 1              1              1               1   \n",
       "1                 1              1              1               1   \n",
       "2                 0              0              0               0   \n",
       "3                 0              0              0               0   \n",
       "4                 0              0              0               0   \n",
       "...             ...            ...            ...             ...   \n",
       "2787              0              0              0               0   \n",
       "2788              0              0              0               0   \n",
       "2789              0              0              0               0   \n",
       "2790              0              0              0               0   \n",
       "2791              0              0              0               0   \n",
       "\n",
       "      192.16.166.2  117.103.111.233  117.103.105.191  ...  72.36.80.78  \\\n",
       "0                1                1                1  ...            0   \n",
       "1                1                0                1  ...            0   \n",
       "2                0                0                0  ...            0   \n",
       "3                0                0                0  ...            0   \n",
       "4                0                0                0  ...            0   \n",
       "...            ...              ...              ...  ...          ...   \n",
       "2787             0                0                0  ...            0   \n",
       "2788             0                0                0  ...            0   \n",
       "2789             0                0                0  ...            1   \n",
       "2790             0                0                0  ...            0   \n",
       "2791             0                0                0  ...            0   \n",
       "\n",
       "      72.36.80.30  146.57.252.194  146.57.252.222  146.57.252.225  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "...           ...             ...             ...             ...   \n",
       "2787            0               0               0               0   \n",
       "2788            0               0               0               0   \n",
       "2789            1               1               1               1   \n",
       "2790            1               1               1               1   \n",
       "2791            1               1               1               1   \n",
       "\n",
       "      146.57.253.217  129.93.6.177  129.93.5.165  72.36.80.80  72.36.96.254  \n",
       "0                  0             0             0            0             0  \n",
       "1                  0             0             0            0             0  \n",
       "2                  0             0             0            0             0  \n",
       "3                  0             0             0            0             0  \n",
       "4                  0             0             0            0             0  \n",
       "...              ...           ...           ...          ...           ...  \n",
       "2787               0             0             0            0             0  \n",
       "2788               0             0             0            0             0  \n",
       "2789               1             1             1            0             0  \n",
       "2790               1             1             1            1             0  \n",
       "2791               1             1             1            1             1  \n",
       "\n",
       "[2792 rows x 2303 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveData(hashDf, 'hashDf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique hops: 2302\n"
     ]
    }
   ],
   "source": [
    "hopsDict = {}\n",
    "\n",
    "for hashKey, hops in list(hashDict.items()):\n",
    "    for hop in hops:\n",
    "        temp = []\n",
    "        if hop in hopsDict.keys():\n",
    "            temp = hopsDict[hop]['hashes']\n",
    "#             if len(temp) > 300:\n",
    "            if hashKey not in temp:\n",
    "                temp.append(hashKey)\n",
    "#             print(len(temp))\n",
    "            hopsDict[hop] = {'hashes': temp, 'num_of_unique_hashes': len(temp)}\n",
    "        else: hopsDict[hop] = {'hashes': [hashKey], 'num_of_unique_hashes': 1}\n",
    "#         print(hop, temp)\n",
    "\n",
    "print(f'Number of unique hops: {len(hopsDict)}')\n",
    "# hopsDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create hops dataframe\n",
    "Add the mean loss for each hop as well as the sum of all packet loss, both based on the paths in which a specific hop takes part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "hopsDf = pd.DataFrame(hopsDict).T.reset_index()\n",
    "\n",
    "aggPathDf = mergedDf.groupby('route-sha1').agg(loss_mean=('loss', 'mean'), loss_sum=('loss', 'sum')).reset_index()\n",
    "def addMeanLoss2Hops(row):\n",
    "    return aggPathDf[aggPathDf['route-sha1'].isin(row['hashes'])]['loss_mean'].mean()\n",
    "\n",
    "def addAccuLoss2Hops(row):\n",
    "    return aggPathDf[aggPathDf['route-sha1'].isin(row['hashes'])]['loss_sum'].sum()\n",
    "\n",
    "hopsDf['mean_loss']=hopsDf.apply(lambda row:addMeanLoss2Hops(row),axis=1)\n",
    "hopsDf['accu_loss']=hopsDf.apply(lambda row:addAccuLoss2Hops(row),axis=1)\n",
    "\n",
    "saveData(hopsDf, 'hopsDf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>hashes</th>\n",
       "      <th>num_of_unique_hashes</th>\n",
       "      <th>mean_loss</th>\n",
       "      <th>accu_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>109.105.124.65</td>\n",
       "      <td>[e64b202e37888601fca7863026cb9f2bb8fc5f8a, 2a6...</td>\n",
       "      <td>17</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>109.105.97.57</td>\n",
       "      <td>[e64b202e37888601fca7863026cb9f2bb8fc5f8a, 2a6...</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>109.105.97.51</td>\n",
       "      <td>[e64b202e37888601fca7863026cb9f2bb8fc5f8a, 2a6...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>192.16.166.86</td>\n",
       "      <td>[e64b202e37888601fca7863026cb9f2bb8fc5f8a, 2a6...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>192.16.166.85</td>\n",
       "      <td>[e64b202e37888601fca7863026cb9f2bb8fc5f8a, 2a6...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            index                                             hashes  \\\n",
       "0  109.105.124.65  [e64b202e37888601fca7863026cb9f2bb8fc5f8a, 2a6...   \n",
       "1   109.105.97.57  [e64b202e37888601fca7863026cb9f2bb8fc5f8a, 2a6...   \n",
       "2   109.105.97.51  [e64b202e37888601fca7863026cb9f2bb8fc5f8a, 2a6...   \n",
       "3   192.16.166.86  [e64b202e37888601fca7863026cb9f2bb8fc5f8a, 2a6...   \n",
       "4   192.16.166.85  [e64b202e37888601fca7863026cb9f2bb8fc5f8a, 2a6...   \n",
       "\n",
       "  num_of_unique_hashes  mean_loss  accu_loss  \n",
       "0                   17   0.000007   0.000139  \n",
       "1                    7   0.000017   0.000139  \n",
       "2                    9   0.000014   0.000139  \n",
       "3                    3   0.000000   0.000000  \n",
       "4                    3   0.000000   0.000000  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hopsDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the distribution of number of unique hashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'temp-plot.html'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig = px.histogram(hopsDf, nbins=50, x=\"num_of_unique_hashes\")\n",
    "py.offline.plot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of hashes to mean packet loss relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'temp-plot.html'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hopsDf = hopsDf.sort_values('num_of_unique_hashes', ascending=False)\n",
    "\n",
    "fig = px.scatter(hopsDf, x='mean_loss', y='num_of_unique_hashes')\n",
    "fig.update_layout(title=f'Num of hashes to mean packet loss relationship' , template='plotly_white')\n",
    "py.offline.plot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>hashes</th>\n",
       "      <th>num_of_unique_hashes</th>\n",
       "      <th>mean_loss</th>\n",
       "      <th>accu_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>192.16.166.158</td>\n",
       "      <td>[5c04fb2256f671a8ef44d7eb9fc77f5597a0241a, 800...</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2153</th>\n",
       "      <td>2001:468:fc:74::2</td>\n",
       "      <td>[42d3ac59b76c34a6253a3ae6a471612e54f8175b, c3a...</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>2001:1458:a00:5::2</td>\n",
       "      <td>[85204832a4778f12ca64b77e5c8b8309a6738c16, 288...</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1269</th>\n",
       "      <td>2001:18e8:804:ff05::1</td>\n",
       "      <td>[1ca6a6a51b4a125c65e61d9e00513159d435b6a7, c4d...</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1262</th>\n",
       "      <td>2001:1458:301:86::2</td>\n",
       "      <td>[2882b30717740b88734f3d794c2066af62e32646, 4c8...</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>146.97.33.22</td>\n",
       "      <td>[532cceda7cdd5f91dd6cdb6c22ae23f73d87fc60, 876...</td>\n",
       "      <td>104</td>\n",
       "      <td>0.132080</td>\n",
       "      <td>12.000468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>146.97.33.42</td>\n",
       "      <td>[876b0add8ece31feb403851cc396d2f15ff94893, 297...</td>\n",
       "      <td>103</td>\n",
       "      <td>0.160005</td>\n",
       "      <td>14.000468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>146.97.36.222</td>\n",
       "      <td>[7fd254eded45bd8c2ee40e906a8285c716d212c0, 40f...</td>\n",
       "      <td>58</td>\n",
       "      <td>0.476197</td>\n",
       "      <td>16.000337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>143.167.3.116</td>\n",
       "      <td>[9804a1959daffa9e0a115d2d429709ef2b3aefb6, 95f...</td>\n",
       "      <td>27</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>146.97.71.82</td>\n",
       "      <td>[9804a1959daffa9e0a115d2d429709ef2b3aefb6, c67...</td>\n",
       "      <td>26</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2302 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      index  \\\n",
       "30           192.16.166.158   \n",
       "2153      2001:468:fc:74::2   \n",
       "1258     2001:1458:a00:5::2   \n",
       "1269  2001:18e8:804:ff05::1   \n",
       "1262    2001:1458:301:86::2   \n",
       "...                     ...   \n",
       "164            146.97.33.22   \n",
       "280            146.97.33.42   \n",
       "210           146.97.36.222   \n",
       "154           143.167.3.116   \n",
       "153            146.97.71.82   \n",
       "\n",
       "                                                 hashes num_of_unique_hashes  \\\n",
       "30    [5c04fb2256f671a8ef44d7eb9fc77f5597a0241a, 800...                    7   \n",
       "2153  [42d3ac59b76c34a6253a3ae6a471612e54f8175b, c3a...                    3   \n",
       "1258  [85204832a4778f12ca64b77e5c8b8309a6738c16, 288...                    3   \n",
       "1269  [1ca6a6a51b4a125c65e61d9e00513159d435b6a7, c4d...                    3   \n",
       "1262  [2882b30717740b88734f3d794c2066af62e32646, 4c8...                    3   \n",
       "...                                                 ...                  ...   \n",
       "164   [532cceda7cdd5f91dd6cdb6c22ae23f73d87fc60, 876...                  104   \n",
       "280   [876b0add8ece31feb403851cc396d2f15ff94893, 297...                  103   \n",
       "210   [7fd254eded45bd8c2ee40e906a8285c716d212c0, 40f...                   58   \n",
       "154   [9804a1959daffa9e0a115d2d429709ef2b3aefb6, 95f...                   27   \n",
       "153   [9804a1959daffa9e0a115d2d429709ef2b3aefb6, c67...                   26   \n",
       "\n",
       "      mean_loss  accu_loss  \n",
       "30     0.000000   0.000000  \n",
       "2153        NaN   0.000000  \n",
       "1258        NaN   0.000000  \n",
       "1269        NaN   0.000000  \n",
       "1262        NaN   0.000000  \n",
       "...         ...        ...  \n",
       "164    0.132080  12.000468  \n",
       "280    0.160005  14.000468  \n",
       "210    0.476197  16.000337  \n",
       "154    1.000000  19.000000  \n",
       "153    1.000000  20.000000  \n",
       "\n",
       "[2302 rows x 5 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hopsDf.sort_values('accu_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
